우리는 `Next.js 15` 환경에서 `@gradio/client`라는 라이브러리를 사용하여, 허깅페이스에 이미 떠 있는 고성능 영상 AI 모델(Wan2.1)을 호출하는 **API 서버 코드**를 만들 것입니다.

---

### 1. 사전 준비 (설치)

터미널(또는 커맨드 창)에서 프로젝트 폴더로 이동한 뒤, 아래 명령어를 입력해 필요한 라이브러리를 설치하세요.

Bash

`npm install @gradio/client`

---

### 2. 영상 생성 API 코드 (`app/api/generate-video/route.ts`)

이 코드는 내 웹사이트 뒷단(서버)에서 허깅페이스 AI에게 "영상 좀 만들어줘!"라고 부탁하고 결과물을 받아오는 역할을 합니다.

TypeScript

`import { client } from "@gradio/client";
import { NextResponse } from "next/server";

export async function POST(request: Request) {
  try {
    // 1. 프론트엔드에서 보낸 영어 프롬프트(설명)를 받습니다.
    const { prompt } = await request.json();

    if (!prompt) {
      return NextResponse.json({ error: "프롬프트가 없습니다." }, { status: 400 });
    }

    // 2. 허깅페이스의 특정 모델 공간(Space)에 연결합니다.
    // 예시 주소: Wan-Video에서 운영하는 Wan2.1 모델
    const app = await client("Wan-Video/Wan2.1-T2V-14B");

    // 3. AI 모델에게 영상 생성을 요청합니다. 
    // .predict(순서, [파라미터들]) 형식인데 모델마다 순서가 다를 수 있습니다.
    const result = await app.predict("/predict", [
      prompt,         // 사용자가 입력한 영어 설명
      "아이디어",      // 보통 부정적인 프롬프트(Negative Prompt) 자리 (비워둬도 됨)
      "1280*720",     // 해상도 설정
      5,              // 영상 길이(초)
    ]);

    // 4. 결과값에서 영상의 URL 주소를 추출합니다.
    // 결과 데이터 구조는 모델마다 다르므로 콘솔로 확인이 필요합니다.
    const videoUrl = result.data[0].url; 

    return NextResponse.json({ url: videoUrl });

  } catch (error) {
    console.error("AI 영상 생성 오류:", error);
    return NextResponse.json(
      { error: "영상 생성 중 오류가 발생했습니다. (대기열 초과 등)" },
      { status: 500 }
    );
  }
}`

---

### 3. 화면에서 버튼 누르면 실행되는 코드 (`components/VideoMaker.tsx`)

이제 실제 화면(UI)에서 위 API를 호출하는 부분입니다.

TypeScript

`"use client";

import { useState } from "react";

export default function VideoMaker() {
  const [prompt, setPrompt] = useState("");
  const [videoUrl, setVideoUrl] = useState("");
  const [isLoading, setIsLoading] = useState(false);

  const handleGenerate = async () => {
    setIsLoading(true);
    try {
      const response = await fetch("/api/generate-video", {
        method: "POST",
        body: JSON.stringify({ prompt }),
      });
      const data = await response.json();
      
      if (data.url) {
        setVideoUrl(data.url);
      } else {
        alert("영상 생성 실패: " + data.error);
      }
    } catch (err) {
      alert("서버 연결 오류");
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="p-4 flex flex-col gap-4">
      <textarea 
        className="border p-2 text-black"
        placeholder="영어 프롬프트를 입력하세요..."
        value={prompt}
        onChange={(e) => setPrompt(e.target.value)}
      />
      
      <button 
        onClick={handleGenerate}
        disabled={isLoading}
        className="bg-blue-500 text-white p-2 rounded disabled:bg-gray-400"
      >
        {isLoading ? "AI가 영상을 그리는 중... (1~3분 소요)" : "영상 만들기"}
      </button>

      {videoUrl && (
        <video src={videoUrl} controls className="w-full mt-4 rounded-lg" />
      )}
    </div>
  );
}`

---

### 💡 초보자를 위한 핵심 설명

1. **Gradio Client:** 마치 우리가 배달 앱으로 음식을 시키듯, 우리 서버가 허깅페이스 서버에 "주문(Prompt)"을 넣고 "음식(Video)"이 배달될 때까지 기다리는 방식입니다.
2. **대기 시간:** 허깅페이스 무료 모델은 전 세계 사람이 같이 쓰기 때문에 `Queue(대기줄)`가 발생합니다. 버튼을 누르고 영상이 나올 때까지 보통 **1분에서 5분** 정도 걸릴 수 있으니 느긋하게 기다려야 합니다.
3. **API 키:** 만약 특정 모델이 'Private'이거나 권한을 요구하면 `hf_...`로 시작하는 허깅페이스 토큰(API Key)을 코드에 추가해야 할 수도 있습니다.